{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Understand some defining characteristics of this data set through EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data\n",
    "file_path = './Senior DS Use Case Exercise.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name='Make Model Count Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Make      Model  Count\n",
      "0    -          -      4\n",
      "1    -          A      1\n",
      "2    -  Altrvar61      1\n",
      "3    ,          ,      1\n",
      "4    ?          ?     11\n",
      "             Make             Model  Count\n",
      "1013267  О. SMITH        ENT-50 110      1\n",
      "1013268  О. SMITH        GCG-50 400      1\n",
      "1013269  О. SMITH       GCRL-40 400      1\n",
      "1013270     用RANE  CMPWPA221ALAEAAA      1\n",
      "1013271   1013272               NaN      0\n"
     ]
    }
   ],
   "source": [
    "## Data Overview - head & tail\n",
    "print(data.head(5))\n",
    "print(data.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1013272 entries, 0 to 1013271\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   Make    1011730 non-null  object\n",
      " 1   Model   1012884 non-null  object\n",
      " 2   Count   1013272 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 23.2+ MB\n",
      "None\n",
      "Summary Statistics:\n",
      "            Make    Model         Count\n",
      "count   1011730  1012884  1.013272e+06\n",
      "unique    13295   909098           NaN\n",
      "top       TRANE       Na           NaN\n",
      "freq     380024      171           NaN\n",
      "mean        NaN      NaN  2.106171e+00\n",
      "std         NaN      NaN  8.948685e+00\n",
      "min         NaN      NaN  0.000000e+00\n",
      "25%         NaN      NaN  1.000000e+00\n",
      "50%         NaN      NaN  1.000000e+00\n",
      "75%         NaN      NaN  1.000000e+00\n",
      "max         NaN      NaN  1.943000e+03\n"
     ]
    }
   ],
   "source": [
    "# understand the structure of the data\n",
    "print(data.info())\n",
    "\n",
    "# The dataset contains 1,013,272 entries (rows). This is indicated by the range index (0 to 1,013,271).\n",
    "# There are a total of 3 columns in the dataset:\n",
    "## The Make column has 1,011,730 non-null entries, indicating that there are 1,542 missing values in this column.\n",
    "## The Model column has 1,012,884 non-null entries, indicating that there are 388 missing values in this column.\n",
    "## The Count column has 1,013,272 non-null entries, which means there are no missing values in this column.\n",
    "##  Memory: The dataset occupies 23.2+ MB of memory.\n",
    "\n",
    "## Overall Summary\n",
    "## Missing Data: Both the \"Make\" and \"Model\" columns have missing values, but the \"Count\" column is complete.\n",
    "## Data Types: The data types are appropriate for the types of data they contain, with \"Make\" and \"Model\" as strings (object) and \"Count\" as an integer.\n",
    "## Dataset Size: With over a million entries, the dataset is quite large, which may have implications for processing time and memory usage in analysis.\n",
    "\n",
    "# summary statistics of the dataset\n",
    "summary_stats = data.describe(include='all')\n",
    "print(\"Summary Statistics:\\n\", summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Make     1542\n",
      "Model     388\n",
      "Count       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Check for Missing Values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing Values:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of Counts\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(data['Count'], bins=20, edgecolor='k')\n",
    "plt.title('Distribution of Counts')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Makes:\n",
      " Make\n",
      "TRANE                    380024\n",
      "OTHER                    122725\n",
      "CARRIER                   80370\n",
      "YORK                      38416\n",
      "LENNOX                    24279\n",
      "DAIKIN                    16594\n",
      "RHEEM                     15861\n",
      "GOODMAN                   15627\n",
      "GREENHECK                 14814\n",
      "INTERNATIONAL COMFORT     12539\n",
      "Name: count, dtype: int64\n",
      "Top 10 Models:\n",
      " Model\n",
      "Na               171\n",
      "N/a               65\n",
      "RG250T6N          62\n",
      "1                 62\n",
      "MECHACS962BT      41\n",
      "Unknown           41\n",
      "RG240S6N          34\n",
      "TBD               32\n",
      "RG240T6N          30\n",
      "RE350S6-1NCWW     26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Top Makes\n",
    "top_makes = data['Make'].value_counts().head(10)\n",
    "print(\"Top 10 Makes:\\n\", top_makes)\n",
    "\n",
    "# Top Models\n",
    "top_models = data['Model'].value_counts().head(10)\n",
    "print(\"Top 10 Models:\\n\", top_models)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary Statistics through EDA:**\n",
    "\n",
    "The dataset contains 1,011,730 records for Make, 1,012,890 records for Model, and 1,013,272 records for Count.\n",
    "\n",
    "There are 13,295 unique Make values and 909,098 unique Model values.\n",
    "\n",
    "The most frequent Make is \"TRANE\" with 380,024 occurrences.\n",
    "\n",
    "The most frequent Model is \"Na\" with 171 occurrences.\n",
    "\n",
    "The Count column ranges from 0 to 1,943 with an average count of approximately 2.11.\n",
    "\n",
    "**Distribution of Count Values:**\n",
    "\n",
    "The distribution of Count values shows a high frequency of lower counts, with a long tail extending towards higher counts\n",
    "\n",
    "**Data Quality Issues:**\n",
    "\n",
    "The dataset contains erroneous values like -, ,, ?, and possibly others that need to be cleaned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Characterize the types of errors we are getting in the Make values and determine the error records**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Error Values and Patterns\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "# List of specific error values\n",
    "error_values = ['-', ',', '?', '????','0','0.00','customer','000']\n",
    "\n",
    "# Regular expression patterns for error detection\n",
    "error_patterns = [\n",
    "    r'^[\\W_]+$',        # Strings with only non-alphanumeric characters\n",
    "    r'^\\?+$',           # Strings with only question marks\n",
    "    r'^\\s*$',           # Empty strings\n",
    "    r'^[A-Za-z]{1,2}$', # Strings with one or two letters (potential typos)\n",
    "    r'^[A-Za-z]{15,}$', # Very long strings (potential typos)\n",
    "    r'^0+$',            # Strings with only zeros\n",
    "    r'^0+\\.\\d+$'        # Strings with '0.' followed by digits\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with Error Values or Patterns:\n",
      "             Make            Model  Count\n",
      "0              -                -      4\n",
      "1              -                A      1\n",
      "2              -        Altrvar61      1\n",
      "3              ,                ,      1\n",
      "4              ?                ?     11\n",
      "..           ...              ...    ...\n",
      "41       0000000             0000      1\n",
      "42       0000000         00000000      2\n",
      "43     000000000         00000000      1\n",
      "45   00000000000  ⁰00000000000000      1\n",
      "46  000000000000       ⁰000000000      1\n",
      "\n",
      "[5265 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify Records with Error Values or Patterns\n",
    "\n",
    "\n",
    "# Ensure all NA/NaN values are filled\n",
    "data['Make'] = data['Make'].fillna('NA')\n",
    "\n",
    "# Filter records with specific error values\n",
    "error_records = data[data['Make'].isin(error_values)]\n",
    "\n",
    "# Filter records matching the error patterns\n",
    "for pattern in error_patterns:\n",
    "    regex_error_records = data[data['Make'].str.contains(pattern, regex=True, na=False)]\n",
    "    error_records = pd.concat([error_records, regex_error_records])\n",
    "\n",
    "# Remove duplicate records if any\n",
    "error_records = error_records.drop_duplicates()\n",
    "\n",
    "# Display the records with error values or patterns\n",
    "print(\"Records with Error Values or Patterns:\\n\", error_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of Specific Error Values:\n",
      " Make\n",
      "-       3\n",
      ",       1\n",
      "?       4\n",
      "0       5\n",
      "0.00    1\n",
      "000     1\n",
      "Name: count, dtype: int64\n",
      "Frequency of pattern '^[\\W_]+$': 25\n",
      "Frequency of pattern '^\\?+$': 9\n",
      "Frequency of pattern '^\\s*$': 0\n",
      "Frequency of pattern '^[A-Za-z]{1,2}$': 4910\n",
      "Frequency of pattern '^[A-Za-z]{15,}$': 322\n",
      "Frequency of pattern '^0+$': 20\n",
      "Frequency of pattern '^0+\\.\\d+$': 1\n"
     ]
    }
   ],
   "source": [
    "# Count the frequency of each specific error value\n",
    "present_error_values = [val for val in error_values if val in data['Make'].values]\n",
    "error_value_counts = data['Make'].value_counts().loc[present_error_values]\n",
    "print(\"Frequency of Specific Error Values:\\n\", error_value_counts)\n",
    "\n",
    "# Count the frequency of error patterns\n",
    "for pattern in error_patterns:\n",
    "    pattern_error_count = data['Make'].str.contains(pattern, regex=True, na=False).sum()\n",
    "    print(f\"Frequency of pattern '{pattern}':\", pattern_error_count)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3.Determine how we can map erroneous Make values to correct Makes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jf/h5v6hnmn5ws_smgb52rl5myw0000gp/T/ipykernel_25228/3743421772.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_cleaned['Make_corrected'] = data_cleaned['Make'].replace(correction_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n",
      "          Make            Model  Count Make_corrected\n",
      "44  0⁰0000000            00000      1      0⁰0000000\n",
      "47  000000009         00000090      1      000000009\n",
      "48     000001           000002      1         000001\n",
      "49        001             0001      1            001\n",
      "50  00 IEBERT  VS070AUA1E1046C      1      00 IEBERT\n",
      "Top Original 'Make' values:\n",
      " Make\n",
      "TRANE                    380024\n",
      "OTHER                    122725\n",
      "CARRIER                   80370\n",
      "YORK                      38416\n",
      "LENNOX                    24279\n",
      "DAIKIN                    16594\n",
      "RHEEM                     15861\n",
      "GOODMAN                   15627\n",
      "GREENHECK                 14814\n",
      "INTERNATIONAL COMFORT     12539\n",
      "AAON                      11515\n",
      "BRYANT                    10168\n",
      "LIEBERT                    9214\n",
      "MCQUAY                     7926\n",
      "MITSUBISHI                 7711\n",
      "HEATCRAFT                  7113\n",
      "LOREN COOK                 6988\n",
      "BARD                       6377\n",
      "RANE                       5791\n",
      "COPELAND                   5392\n",
      "Name: count, dtype: int64\n",
      "Top Corrected 'Make' values:\n",
      " Make_corrected\n",
      "TRANE                    381386\n",
      "OTHER                    122730\n",
      "CARRIER                   80721\n",
      "YORK                      38452\n",
      "LENNOX                    24584\n",
      "DAIKIN                    16832\n",
      "RHEEM                     16346\n",
      "GOODMAN                   15883\n",
      "GREENHECK                 14876\n",
      "INTERNATIONAL COMFORT     12596\n",
      "AAON                      11610\n",
      "BRYANT                    10336\n",
      "LIEBERT                    9355\n",
      "MCQUAY                     7995\n",
      "MITSUBISHI                 7772\n",
      "HEATCRAFT                  7209\n",
      "LOREN COOK                 7006\n",
      "BARD                       6474\n",
      "RANE                       5953\n",
      "COPELAND                   5489\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import Levenshtein\n",
    "\n",
    "\n",
    "# List of common erroneous values and patterns\n",
    "erroneous_values = ['-', ',', '?', '????', '0', '0.00', 'customer', '000']\n",
    "erroneous_patterns = [\n",
    "    r'^[\\W_]+$', r'^\\?+$', r'^\\s*$', r'^[A-Za-z]{1,2}$', r'^[A-Za-z]{15,}$', r'^0+$', r'^0+\\.\\d+$'\n",
    "]\n",
    "\n",
    "# Function to check if a value is erroneous\n",
    "def is_erroneous(value):\n",
    "    value = str(value)  # Ensure the value is a string\n",
    "    if value in erroneous_values:\n",
    "        return True\n",
    "    for pattern in erroneous_patterns:\n",
    "        if re.match(pattern, value):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Ensure all 'Make' values are strings\n",
    "data['Make'] = data['Make'].astype(str)\n",
    "\n",
    "# Filter out nonsensical rows\n",
    "data_cleaned = data[~data['Make'].apply(is_erroneous)]\n",
    "\n",
    "# Get the list of top makes to use as correct values\n",
    "top_makes = data_cleaned['Make'].value_counts().head(50).index.tolist()  # Consider top 50 makes as correct values\n",
    "\n",
    "# Function to find the closest matches using Levenshtein distance\n",
    "def find_closest_match(value, possibilities):\n",
    "    if not possibilities:\n",
    "        return value\n",
    "    closest_match = min(possibilities, key=lambda x: Levenshtein.distance(str(value), str(x)))\n",
    "    return closest_match\n",
    "\n",
    "# Create a correction mapping based on exact matches\n",
    "correction_mapping = {}\n",
    "for error_value in data_cleaned['Make'].unique():\n",
    "    if error_value not in top_makes and not is_erroneous(error_value):\n",
    "        closest_match = find_closest_match(error_value, top_makes)\n",
    "        if Levenshtein.distance(error_value, closest_match) <= 1:  # Use a threshold to decide if it's close enough\n",
    "            correction_mapping[error_value] = closest_match\n",
    "\n",
    "# Apply the correction mapping\n",
    "data_cleaned['Make_corrected'] = data_cleaned['Make'].replace(correction_mapping)\n",
    "\n",
    "# Remove any rows where the 'Make_corrected' values are still nonsensical\n",
    "data_cleaned = data_cleaned[~data_cleaned['Make_corrected'].apply(is_erroneous)]\n",
    "\n",
    "# Display the cleaned data\n",
    "print(\"Cleaned Data:\\n\", data_cleaned.head())\n",
    "\n",
    "# Display the top value counts for original and corrected 'Make' values\n",
    "print(\"Top Original 'Make' values:\\n\", data['Make'].value_counts().head(20))\n",
    "print(\"Top Corrected 'Make' values:\\n\", data_cleaned['Make_corrected'].value_counts().head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Investigate building a model to predict the Make from the Model data. How would we go about doing this?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation, which will be used across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'data' is your DataFrame containing 'Model' and 'Make_corrected' columns\n",
    "\n",
    "# Prepare features and target\n",
    "X = data_cleaned['Model'].fillna('missing').astype(str)  # Ensure all values are strings\n",
    "y = data_cleaned['Make_corrected'].astype(str)  # Ensure all values are strings\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Function to visualize the confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Function to print evaluation metrics\n",
    "def print_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with TfidfVectorizer and MultinomialNB\n",
    "model_nb = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_nb = model_nb.predict(X_test)\n",
    "print(\"Naive Bayes Classification Report\")\n",
    "print_metrics(y_test, y_pred_nb)\n",
    "plot_confusion_matrix(y_test, y_pred_nb, label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the model\n",
    "clf_rf = RandomForestClassifier()\n",
    "clf_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = clf_rf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classification Report\")\n",
    "print_metrics(y_test, y_pred_rf)\n",
    "plot_confusion_matrix(y_test, y_pred_rf, label_encoder.classes_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## SVM \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train the model\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = clf_svm.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Classification Report\")\n",
    "print_metrics(y_test, y_pred_svm)\n",
    "plot_confusion_matrix(y_test, y_pred_svm, label_encoder.classes_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT for Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5328ca65948749d99f81827cf83d8456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50664 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 9.3929, 'grad_norm': 7.623600006103516, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n",
      "{'loss': 9.3048, 'grad_norm': 9.139775276184082, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n",
      "{'loss': 9.2022, 'grad_norm': 10.413771629333496, 'learning_rate': 3e-06, 'epoch': 0.0}\n",
      "{'loss': 9.1162, 'grad_norm': 9.446459770202637, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 8.9732, 'grad_norm': 9.85116195678711, 'learning_rate': 5e-06, 'epoch': 0.0}\n",
      "{'loss': 8.9263, 'grad_norm': 10.263567924499512, 'learning_rate': 6e-06, 'epoch': 0.0}\n",
      "{'loss': 8.8266, 'grad_norm': 12.417312622070312, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 8.5551, 'grad_norm': 11.650422096252441, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}\n",
      "{'loss': 8.4918, 'grad_norm': 11.366101264953613, 'learning_rate': 9e-06, 'epoch': 0.0}\n",
      "{'loss': 8.1049, 'grad_norm': 12.465200424194336, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 7.9525, 'grad_norm': 12.164595603942871, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.0}\n",
      "{'loss': 7.7758, 'grad_norm': 8.254498481750488, 'learning_rate': 1.2e-05, 'epoch': 0.0}\n",
      "{'loss': 7.2827, 'grad_norm': 11.51234245300293, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.0}\n",
      "{'loss': 7.0944, 'grad_norm': 8.100292205810547, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.0}\n",
      "{'loss': 6.6608, 'grad_norm': 7.974365234375, 'learning_rate': 1.5e-05, 'epoch': 0.0}\n",
      "{'loss': 6.8912, 'grad_norm': 7.391941070556641, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 6.4157, 'grad_norm': 6.4256978034973145, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 6.0633, 'grad_norm': 6.454860210418701, 'learning_rate': 1.8e-05, 'epoch': 0.0}\n",
      "{'loss': 5.5602, 'grad_norm': 6.407032012939453, 'learning_rate': 1.9e-05, 'epoch': 0.0}\n",
      "{'loss': 5.091, 'grad_norm': 6.951286792755127, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 5.0569, 'grad_norm': 6.701420307159424, 'learning_rate': 2.1e-05, 'epoch': 0.0}\n",
      "{'loss': 4.9445, 'grad_norm': 5.0490217208862305, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 5.128, 'grad_norm': 6.482076644897461, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.0}\n",
      "{'loss': 4.4292, 'grad_norm': 6.780595302581787, 'learning_rate': 2.4e-05, 'epoch': 0.0}\n",
      "{'loss': 4.0827, 'grad_norm': 6.174128532409668, 'learning_rate': 2.5e-05, 'epoch': 0.0}\n",
      "{'loss': 4.1946, 'grad_norm': 5.681021690368652, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 4.0063, 'grad_norm': 5.877871036529541, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.01}\n",
      "{'loss': 3.747, 'grad_norm': 6.037787914276123, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.01}\n",
      "{'loss': 3.8214, 'grad_norm': 5.919368743896484, 'learning_rate': 2.9e-05, 'epoch': 0.01}\n",
      "{'loss': 4.1943, 'grad_norm': 6.401218891143799, 'learning_rate': 3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.9664, 'grad_norm': 8.130745887756348, 'learning_rate': 3.1e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1145, 'grad_norm': 5.557408809661865, 'learning_rate': 3.2000000000000005e-05, 'epoch': 0.01}\n",
      "{'loss': 3.1026, 'grad_norm': 5.672029972076416, 'learning_rate': 3.3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3287, 'grad_norm': 6.197662830352783, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.01}\n",
      "{'loss': 3.2981, 'grad_norm': 6.369438171386719, 'learning_rate': 3.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0692, 'grad_norm': 6.791299343109131, 'learning_rate': 3.6e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7807, 'grad_norm': 5.596980571746826, 'learning_rate': 3.7e-05, 'epoch': 0.01}\n",
      "{'loss': 3.3059, 'grad_norm': 5.10087251663208, 'learning_rate': 3.8e-05, 'epoch': 0.01}\n",
      "{'loss': 2.718, 'grad_norm': 5.593014240264893, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 3.4844, 'grad_norm': 5.25612735748291, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0929, 'grad_norm': 4.638542652130127, 'learning_rate': 4.1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9528, 'grad_norm': 5.30435848236084, 'learning_rate': 4.2e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9569, 'grad_norm': 6.11100959777832, 'learning_rate': 4.3e-05, 'epoch': 0.01}\n",
      "{'loss': 3.2076, 'grad_norm': 5.179050922393799, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8109, 'grad_norm': 4.5574564933776855, 'learning_rate': 4.5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.0289, 'grad_norm': 8.813261985778809, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2101, 'grad_norm': 4.273831844329834, 'learning_rate': 4.7e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9802, 'grad_norm': 4.980371475219727, 'learning_rate': 4.8e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8263, 'grad_norm': 5.181325912475586, 'learning_rate': 4.9e-05, 'epoch': 0.01}\n",
      "{'loss': 2.6812, 'grad_norm': 4.395896911621094, 'learning_rate': 5e-05, 'epoch': 0.01}\n",
      "{'loss': 3.2921, 'grad_norm': 8.092456817626953, 'learning_rate': 4.9990032692767724e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7148, 'grad_norm': 7.9293928146362305, 'learning_rate': 4.9980065385535445e-05, 'epoch': 0.01}\n",
      "{'loss': 2.5456, 'grad_norm': 5.25710391998291, 'learning_rate': 4.997009807830317e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9059, 'grad_norm': 14.070326805114746, 'learning_rate': 4.996013077107089e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8585, 'grad_norm': 6.587035655975342, 'learning_rate': 4.995016346383861e-05, 'epoch': 0.01}\n",
      "{'loss': 2.5053, 'grad_norm': 6.242527961730957, 'learning_rate': 4.994019615660633e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7282, 'grad_norm': 6.5369133949279785, 'learning_rate': 4.993022884937405e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8464, 'grad_norm': 5.888619899749756, 'learning_rate': 4.9920261542141775e-05, 'epoch': 0.01}\n",
      "{'loss': 2.5325, 'grad_norm': 5.548352241516113, 'learning_rate': 4.9910294234909496e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4506, 'grad_norm': 3.9918644428253174, 'learning_rate': 4.990032692767722e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9171, 'grad_norm': 8.186019897460938, 'learning_rate': 4.9890359620444946e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9182, 'grad_norm': 4.586432456970215, 'learning_rate': 4.988039231321267e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4761, 'grad_norm': 6.292386054992676, 'learning_rate': 4.987042500598039e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4566, 'grad_norm': 5.100518703460693, 'learning_rate': 4.986045769874811e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3371, 'grad_norm': 5.682477951049805, 'learning_rate': 4.985049039151583e-05, 'epoch': 0.01}\n",
      "{'loss': 2.569, 'grad_norm': 4.540101528167725, 'learning_rate': 4.9840523084283554e-05, 'epoch': 0.01}\n",
      "{'loss': 2.5777, 'grad_norm': 4.6612420082092285, 'learning_rate': 4.9830555777051275e-05, 'epoch': 0.01}\n",
      "{'loss': 3.25, 'grad_norm': 6.594632148742676, 'learning_rate': 4.9820588469819e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7926, 'grad_norm': 8.160840034484863, 'learning_rate': 4.981062116258672e-05, 'epoch': 0.01}\n",
      "{'loss': 2.3873, 'grad_norm': 4.5481648445129395, 'learning_rate': 4.980065385535444e-05, 'epoch': 0.01}\n",
      "{'loss': 2.5327, 'grad_norm': 5.889683246612549, 'learning_rate': 4.979068654812216e-05, 'epoch': 0.01}\n",
      "{'loss': 2.9441, 'grad_norm': 7.090351581573486, 'learning_rate': 4.978071924088988e-05, 'epoch': 0.01}\n",
      "{'loss': 2.7668, 'grad_norm': 6.671011447906494, 'learning_rate': 4.9770751933657605e-05, 'epoch': 0.01}\n",
      "{'loss': 2.4061, 'grad_norm': 11.872970581054688, 'learning_rate': 4.9760784626425326e-05, 'epoch': 0.01}\n",
      "{'loss': 2.6792, 'grad_norm': 7.822828769683838, 'learning_rate': 4.975081731919305e-05, 'epoch': 0.01}\n",
      "{'loss': 2.8753, 'grad_norm': 3.992018222808838, 'learning_rate': 4.974085001196077e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6898, 'grad_norm': 5.9061102867126465, 'learning_rate': 4.973088270472849e-05, 'epoch': 0.02}\n",
      "{'loss': 2.7447, 'grad_norm': 6.069164752960205, 'learning_rate': 4.972091539749621e-05, 'epoch': 0.02}\n",
      "{'loss': 2.9579, 'grad_norm': 6.39683198928833, 'learning_rate': 4.9710948090263934e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5868, 'grad_norm': 4.476336479187012, 'learning_rate': 4.9700980783031655e-05, 'epoch': 0.02}\n",
      "{'loss': 2.3616, 'grad_norm': 3.8906476497650146, 'learning_rate': 4.9691013475799384e-05, 'epoch': 0.02}\n",
      "{'loss': 2.257, 'grad_norm': 8.568703651428223, 'learning_rate': 4.9681046168567105e-05, 'epoch': 0.02}\n",
      "{'loss': 2.9816, 'grad_norm': 4.523575305938721, 'learning_rate': 4.967107886133483e-05, 'epoch': 0.02}\n",
      "{'loss': 2.7988, 'grad_norm': 5.2204670906066895, 'learning_rate': 4.966111155410255e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8403, 'grad_norm': 6.639702320098877, 'learning_rate': 4.965114424687027e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6639, 'grad_norm': 6.429667949676514, 'learning_rate': 4.964117693963799e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8443, 'grad_norm': 5.501012802124023, 'learning_rate': 4.963120963240571e-05, 'epoch': 0.02}\n",
      "{'loss': 2.785, 'grad_norm': 6.525665283203125, 'learning_rate': 4.9621242325173435e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4429, 'grad_norm': 5.369761943817139, 'learning_rate': 4.9611275017941156e-05, 'epoch': 0.02}\n",
      "{'loss': 3.2283, 'grad_norm': 9.151277542114258, 'learning_rate': 4.960130771070888e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6708, 'grad_norm': 5.333501815795898, 'learning_rate': 4.95913404034766e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5761, 'grad_norm': 5.113830089569092, 'learning_rate': 4.958137309624432e-05, 'epoch': 0.02}\n",
      "{'loss': 3.1302, 'grad_norm': 5.454326152801514, 'learning_rate': 4.957140578901204e-05, 'epoch': 0.02}\n",
      "{'loss': 2.3113, 'grad_norm': 7.996475696563721, 'learning_rate': 4.9561438481779764e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6466, 'grad_norm': 5.715712547302246, 'learning_rate': 4.9551471174547485e-05, 'epoch': 0.02}\n",
      "{'loss': 2.507, 'grad_norm': 10.219441413879395, 'learning_rate': 4.954150386731521e-05, 'epoch': 0.02}\n",
      "{'loss': 3.0731, 'grad_norm': 7.119412422180176, 'learning_rate': 4.953153656008293e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5828, 'grad_norm': 5.204545497894287, 'learning_rate': 4.952156925285065e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6337, 'grad_norm': 5.916284084320068, 'learning_rate': 4.951160194561837e-05, 'epoch': 0.02}\n",
      "{'loss': 2.7053, 'grad_norm': 7.168686866760254, 'learning_rate': 4.950163463838609e-05, 'epoch': 0.02}\n",
      "{'loss': 2.9659, 'grad_norm': 6.036257266998291, 'learning_rate': 4.949166733115382e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8574, 'grad_norm': 6.921143531799316, 'learning_rate': 4.948170002392154e-05, 'epoch': 0.02}\n",
      "{'loss': 2.3593, 'grad_norm': 5.236725807189941, 'learning_rate': 4.9471732716689264e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2135, 'grad_norm': 9.167691230773926, 'learning_rate': 4.9461765409456986e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5087, 'grad_norm': 4.765446662902832, 'learning_rate': 4.945179810222471e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6946, 'grad_norm': 7.576173782348633, 'learning_rate': 4.944183079499243e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4262, 'grad_norm': 13.168006896972656, 'learning_rate': 4.943186348776015e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6379, 'grad_norm': 7.161839485168457, 'learning_rate': 4.942189618052787e-05, 'epoch': 0.02}\n",
      "{'loss': 2.532, 'grad_norm': 5.4136834144592285, 'learning_rate': 4.9411928873295594e-05, 'epoch': 0.02}\n",
      "{'loss': 2.7979, 'grad_norm': 12.647791862487793, 'learning_rate': 4.9401961566063315e-05, 'epoch': 0.02}\n",
      "{'loss': 2.262, 'grad_norm': 8.871904373168945, 'learning_rate': 4.939199425883104e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2666, 'grad_norm': 5.701490879058838, 'learning_rate': 4.938202695159876e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4317, 'grad_norm': 7.919548511505127, 'learning_rate': 4.937205964436648e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5866, 'grad_norm': 6.739492416381836, 'learning_rate': 4.93620923371342e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6, 'grad_norm': 4.525982856750488, 'learning_rate': 4.935212502990192e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4293, 'grad_norm': 4.54325008392334, 'learning_rate': 4.9342157722669644e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8137, 'grad_norm': 6.177969455718994, 'learning_rate': 4.9332190415437366e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8519, 'grad_norm': 6.422110080718994, 'learning_rate': 4.932222310820509e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8075, 'grad_norm': 8.189837455749512, 'learning_rate': 4.931225580097281e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4017, 'grad_norm': 5.683344841003418, 'learning_rate': 4.930228849374053e-05, 'epoch': 0.02}\n",
      "{'loss': 2.5995, 'grad_norm': 5.249485969543457, 'learning_rate': 4.929232118650826e-05, 'epoch': 0.02}\n",
      "{'loss': 2.8369, 'grad_norm': 4.85294771194458, 'learning_rate': 4.928235387927598e-05, 'epoch': 0.02}\n",
      "{'loss': 2.4975, 'grad_norm': 7.089889049530029, 'learning_rate': 4.92723865720437e-05, 'epoch': 0.02}\n",
      "{'loss': 2.402, 'grad_norm': 5.440659523010254, 'learning_rate': 4.9262419264811424e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6238, 'grad_norm': 8.781875610351562, 'learning_rate': 4.9252451957579145e-05, 'epoch': 0.02}\n",
      "{'loss': 2.2379, 'grad_norm': 5.403359413146973, 'learning_rate': 4.924248465034687e-05, 'epoch': 0.02}\n",
      "{'loss': 2.6411, 'grad_norm': 6.424050331115723, 'learning_rate': 4.923251734311459e-05, 'epoch': 0.03}\n",
      "{'loss': 2.8067, 'grad_norm': 5.861265182495117, 'learning_rate': 4.922255003588231e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4192, 'grad_norm': 3.7874579429626465, 'learning_rate': 4.921258272865003e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4159, 'grad_norm': 5.398421764373779, 'learning_rate': 4.920261542141775e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4693, 'grad_norm': 4.677947998046875, 'learning_rate': 4.9192648114185474e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4446, 'grad_norm': 6.84006404876709, 'learning_rate': 4.9182680806953196e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3791, 'grad_norm': 6.482789516448975, 'learning_rate': 4.917271349972092e-05, 'epoch': 0.03}\n",
      "{'loss': 2.7109, 'grad_norm': 6.5409979820251465, 'learning_rate': 4.916274619248864e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4084, 'grad_norm': 6.506781101226807, 'learning_rate': 4.915277888525636e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3648, 'grad_norm': 5.038753986358643, 'learning_rate': 4.914281157802408e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4791, 'grad_norm': 8.072175025939941, 'learning_rate': 4.9132844270791804e-05, 'epoch': 0.03}\n",
      "{'loss': 2.538, 'grad_norm': 5.0068793296813965, 'learning_rate': 4.9122876963559525e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4711, 'grad_norm': 6.714425086975098, 'learning_rate': 4.911290965632725e-05, 'epoch': 0.03}\n",
      "{'loss': 2.7091, 'grad_norm': 7.8250322341918945, 'learning_rate': 4.910294234909497e-05, 'epoch': 0.03}\n",
      "{'loss': 2.6044, 'grad_norm': 10.065203666687012, 'learning_rate': 4.9092975041862697e-05, 'epoch': 0.03}\n",
      "{'loss': 2.7089, 'grad_norm': 6.900691986083984, 'learning_rate': 4.908300773463042e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3191, 'grad_norm': 5.404939651489258, 'learning_rate': 4.907304042739814e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4349, 'grad_norm': 5.016724586486816, 'learning_rate': 4.906307312016586e-05, 'epoch': 0.03}\n",
      "{'loss': 2.627, 'grad_norm': 5.675320625305176, 'learning_rate': 4.905310581293358e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0783, 'grad_norm': 5.292880058288574, 'learning_rate': 4.9043138505701304e-05, 'epoch': 0.03}\n",
      "{'loss': 2.9761, 'grad_norm': 5.760403633117676, 'learning_rate': 4.9033171198469026e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2845, 'grad_norm': 5.207409858703613, 'learning_rate': 4.902320389123675e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3583, 'grad_norm': 6.320450305938721, 'learning_rate': 4.901323658400447e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5789, 'grad_norm': 7.459409236907959, 'learning_rate': 4.900326927677219e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5907, 'grad_norm': 9.063118934631348, 'learning_rate': 4.899330196953991e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4794, 'grad_norm': 5.875870227813721, 'learning_rate': 4.8983334662307634e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3061, 'grad_norm': 7.625999450683594, 'learning_rate': 4.8973367355075355e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5672, 'grad_norm': 6.02218770980835, 'learning_rate': 4.896340004784308e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0386, 'grad_norm': 6.125838279724121, 'learning_rate': 4.89534327406108e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4318, 'grad_norm': 5.295584678649902, 'learning_rate': 4.894346543337852e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3818, 'grad_norm': 6.414120197296143, 'learning_rate': 4.893349812614624e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4354, 'grad_norm': 11.394880294799805, 'learning_rate': 4.892353081891396e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4771, 'grad_norm': 4.960670471191406, 'learning_rate': 4.8913563511681684e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1274, 'grad_norm': 5.928201675415039, 'learning_rate': 4.8903596204449406e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2083, 'grad_norm': 8.104619979858398, 'learning_rate': 4.889362889721713e-05, 'epoch': 0.03}\n",
      "{'loss': 2.6178, 'grad_norm': 10.71887493133545, 'learning_rate': 4.8883661589984856e-05, 'epoch': 0.03}\n",
      "{'loss': 2.399, 'grad_norm': 7.476958751678467, 'learning_rate': 4.887369428275258e-05, 'epoch': 0.03}\n",
      "{'loss': 2.6832, 'grad_norm': 7.292619705200195, 'learning_rate': 4.88637269755203e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4378, 'grad_norm': 7.934796333312988, 'learning_rate': 4.885375966828802e-05, 'epoch': 0.03}\n",
      "{'loss': 3.0, 'grad_norm': 8.899739265441895, 'learning_rate': 4.884379236105574e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5481, 'grad_norm': 8.548203468322754, 'learning_rate': 4.8833825053823463e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3547, 'grad_norm': 6.840019702911377, 'learning_rate': 4.8823857746591185e-05, 'epoch': 0.03}\n",
      "{'loss': 2.7632, 'grad_norm': 7.696831703186035, 'learning_rate': 4.8813890439358907e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1804, 'grad_norm': 6.115993976593018, 'learning_rate': 4.880392313212663e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9963, 'grad_norm': 6.193757057189941, 'learning_rate': 4.879395582489435e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0471, 'grad_norm': 4.566916465759277, 'learning_rate': 4.878398851766207e-05, 'epoch': 0.03}\n",
      "{'loss': 2.5635, 'grad_norm': 7.645506381988525, 'learning_rate': 4.877402121042979e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3785, 'grad_norm': 4.722963333129883, 'learning_rate': 4.8764053903197514e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2218, 'grad_norm': 7.1281609535217285, 'learning_rate': 4.8754086595965236e-05, 'epoch': 0.03}\n",
      "{'loss': 2.4127, 'grad_norm': 6.840122699737549, 'learning_rate': 4.874411928873296e-05, 'epoch': 0.03}\n",
      "{'loss': 2.3904, 'grad_norm': 5.502452373504639, 'learning_rate': 4.873415198150068e-05, 'epoch': 0.03}\n",
      "{'loss': 2.7245, 'grad_norm': 6.610609531402588, 'learning_rate': 4.87241846742684e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3657, 'grad_norm': 6.669033527374268, 'learning_rate': 4.871421736703612e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2578, 'grad_norm': 7.600475311279297, 'learning_rate': 4.8704250059803844e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4097, 'grad_norm': 10.556072235107422, 'learning_rate': 4.8694282752571565e-05, 'epoch': 0.04}\n",
      "{'loss': 2.1482, 'grad_norm': 7.23928165435791, 'learning_rate': 4.868431544533929e-05, 'epoch': 0.04}\n",
      "{'loss': 2.5141, 'grad_norm': 7.145072937011719, 'learning_rate': 4.8674348138107015e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4422, 'grad_norm': 4.760529518127441, 'learning_rate': 4.8664380830874736e-05, 'epoch': 0.04}\n",
      "{'loss': 2.1193, 'grad_norm': 5.193927764892578, 'learning_rate': 4.865441352364246e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7269, 'grad_norm': 4.958964824676514, 'learning_rate': 4.864444621641018e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3143, 'grad_norm': 6.616258144378662, 'learning_rate': 4.86344789091779e-05, 'epoch': 0.04}\n",
      "{'loss': 1.941, 'grad_norm': 6.610617160797119, 'learning_rate': 4.862451160194562e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3391, 'grad_norm': 6.973080635070801, 'learning_rate': 4.8614544294713344e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9287, 'grad_norm': 8.39281940460205, 'learning_rate': 4.8604576987481066e-05, 'epoch': 0.04}\n",
      "{'loss': 2.457, 'grad_norm': 5.632262229919434, 'learning_rate': 4.859460968024879e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8174, 'grad_norm': 6.1464314460754395, 'learning_rate': 4.858464237301651e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3121, 'grad_norm': 6.457364559173584, 'learning_rate': 4.857467506578423e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3849, 'grad_norm': 5.6554741859436035, 'learning_rate': 4.856470775855195e-05, 'epoch': 0.04}\n",
      "{'loss': 2.607, 'grad_norm': 5.388401031494141, 'learning_rate': 4.8554740451319673e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3075, 'grad_norm': 8.76150894165039, 'learning_rate': 4.8544773144087395e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3341, 'grad_norm': 6.487030982971191, 'learning_rate': 4.8534805836855116e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2298, 'grad_norm': 3.6563353538513184, 'learning_rate': 4.852483852962284e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4568, 'grad_norm': 5.566558837890625, 'learning_rate': 4.851487122239056e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9064, 'grad_norm': 7.264807224273682, 'learning_rate': 4.850490391515828e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8807, 'grad_norm': 8.231552124023438, 'learning_rate': 4.8494936607926e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4278, 'grad_norm': 6.487994194030762, 'learning_rate': 4.848496930069373e-05, 'epoch': 0.04}\n",
      "{'loss': 2.6651, 'grad_norm': 7.132775783538818, 'learning_rate': 4.847500199346145e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9882, 'grad_norm': 5.145430088043213, 'learning_rate': 4.8465034686229174e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9952, 'grad_norm': 4.226136684417725, 'learning_rate': 4.8455067378996896e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2854, 'grad_norm': 12.247125625610352, 'learning_rate': 4.844510007176462e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2333, 'grad_norm': 5.877339839935303, 'learning_rate': 4.843513276453234e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0995, 'grad_norm': 7.939274311065674, 'learning_rate': 4.842516545730006e-05, 'epoch': 0.04}\n",
      "{'loss': 2.1512, 'grad_norm': 9.090160369873047, 'learning_rate': 4.841519815006778e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9767, 'grad_norm': 6.308282375335693, 'learning_rate': 4.84052308428355e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4655, 'grad_norm': 5.778687477111816, 'learning_rate': 4.8395263535603225e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2935, 'grad_norm': 6.1989545822143555, 'learning_rate': 4.8385296228370946e-05, 'epoch': 0.04}\n",
      "{'loss': 2.394, 'grad_norm': 8.996866226196289, 'learning_rate': 4.837532892113867e-05, 'epoch': 0.04}\n",
      "{'loss': 2.472, 'grad_norm': 5.908200263977051, 'learning_rate': 4.836536161390639e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3529, 'grad_norm': 10.478358268737793, 'learning_rate': 4.835539430667411e-05, 'epoch': 0.04}\n",
      "{'loss': 2.2269, 'grad_norm': 5.3026533126831055, 'learning_rate': 4.834542699944183e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4284, 'grad_norm': 4.6655731201171875, 'learning_rate': 4.8335459692209554e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7467, 'grad_norm': 4.064818382263184, 'learning_rate': 4.8325492384977276e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4505, 'grad_norm': 6.914961338043213, 'learning_rate': 4.8315525077745e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3346, 'grad_norm': 9.042749404907227, 'learning_rate': 4.830555777051272e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3563, 'grad_norm': 9.908479690551758, 'learning_rate': 4.829559046328044e-05, 'epoch': 0.04}\n",
      "{'loss': 2.4063, 'grad_norm': 6.728207588195801, 'learning_rate': 4.828562315604817e-05, 'epoch': 0.04}\n",
      "{'loss': 2.1177, 'grad_norm': 6.755774021148682, 'learning_rate': 4.827565584881589e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3231, 'grad_norm': 7.9425225257873535, 'learning_rate': 4.826568854158361e-05, 'epoch': 0.04}\n",
      "{'loss': 2.3368, 'grad_norm': 9.113978385925293, 'learning_rate': 4.825572123435133e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9377, 'grad_norm': 4.792013168334961, 'learning_rate': 4.8245753927119055e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9818, 'grad_norm': 7.810209274291992, 'learning_rate': 4.8235786619886776e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9218, 'grad_norm': 9.251574516296387, 'learning_rate': 4.82258193126545e-05, 'epoch': 0.05}\n",
      "{'loss': 2.202, 'grad_norm': 6.337789058685303, 'learning_rate': 4.821585200542222e-05, 'epoch': 0.05}\n",
      "{'loss': 2.5642, 'grad_norm': 11.891610145568848, 'learning_rate': 4.820588469818994e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0074, 'grad_norm': 7.018002510070801, 'learning_rate': 4.819591739095766e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3165, 'grad_norm': 6.5103983879089355, 'learning_rate': 4.8185950083725384e-05, 'epoch': 0.05}\n",
      "{'loss': 2.4671, 'grad_norm': 7.499825477600098, 'learning_rate': 4.8175982776493106e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1586, 'grad_norm': 5.1054463386535645, 'learning_rate': 4.816601546926083e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0115, 'grad_norm': 8.704377174377441, 'learning_rate': 4.815604816202855e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1975, 'grad_norm': 5.015684604644775, 'learning_rate': 4.814608085479627e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9749, 'grad_norm': 7.383458137512207, 'learning_rate': 4.813611354756399e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3396, 'grad_norm': 4.433927059173584, 'learning_rate': 4.812614624033171e-05, 'epoch': 0.05}\n",
      "{'loss': 1.954, 'grad_norm': 6.516887664794922, 'learning_rate': 4.8116178933099435e-05, 'epoch': 0.05}\n",
      "{'loss': 1.7852, 'grad_norm': 6.211080551147461, 'learning_rate': 4.8106211625867156e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9504, 'grad_norm': 5.704206943511963, 'learning_rate': 4.809624431863488e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9236, 'grad_norm': 11.425272941589355, 'learning_rate': 4.8086277011402606e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9483, 'grad_norm': 6.389084815979004, 'learning_rate': 4.807630970417033e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2623, 'grad_norm': 6.105751037597656, 'learning_rate': 4.806634239693805e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8275, 'grad_norm': 6.140872955322266, 'learning_rate': 4.805637508970577e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9515, 'grad_norm': 8.352113723754883, 'learning_rate': 4.804640778247349e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2169, 'grad_norm': 7.505736827850342, 'learning_rate': 4.8036440475241214e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1657, 'grad_norm': 9.207975387573242, 'learning_rate': 4.8026473168008935e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0994, 'grad_norm': 7.332864284515381, 'learning_rate': 4.801650586077666e-05, 'epoch': 0.05}\n",
      "{'loss': 2.206, 'grad_norm': 8.896954536437988, 'learning_rate': 4.800653855354438e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8883, 'grad_norm': 4.079469203948975, 'learning_rate': 4.79965712463121e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3783, 'grad_norm': 5.166968822479248, 'learning_rate': 4.798660393907982e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0663, 'grad_norm': 11.509214401245117, 'learning_rate': 4.797663663184754e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0518, 'grad_norm': 5.0053181648254395, 'learning_rate': 4.7966669324615265e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1632, 'grad_norm': 10.033665657043457, 'learning_rate': 4.7956702017382986e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1758, 'grad_norm': 5.795132637023926, 'learning_rate': 4.794673471015071e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3948, 'grad_norm': 7.4898223876953125, 'learning_rate': 4.793676740291843e-05, 'epoch': 0.05}\n",
      "{'loss': 1.7468, 'grad_norm': 4.399419784545898, 'learning_rate': 4.792680009568615e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1087, 'grad_norm': 13.329583168029785, 'learning_rate': 4.791683278845387e-05, 'epoch': 0.05}\n",
      "{'loss': 2.7596, 'grad_norm': 6.945324897766113, 'learning_rate': 4.7906865481221594e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8812, 'grad_norm': 5.142016410827637, 'learning_rate': 4.7896898173989316e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1782, 'grad_norm': 10.60111141204834, 'learning_rate': 4.7886930866757044e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1931, 'grad_norm': 7.971285820007324, 'learning_rate': 4.7876963559524765e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1828, 'grad_norm': 5.547184944152832, 'learning_rate': 4.786699625229249e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3101, 'grad_norm': 9.161012649536133, 'learning_rate': 4.785702894506021e-05, 'epoch': 0.05}\n",
      "{'loss': 2.3197, 'grad_norm': 10.105772972106934, 'learning_rate': 4.784706163782793e-05, 'epoch': 0.05}\n",
      "{'loss': 1.7735, 'grad_norm': 4.975625038146973, 'learning_rate': 4.783709433059565e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0311, 'grad_norm': 8.780044555664062, 'learning_rate': 4.782712702336337e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1669, 'grad_norm': 6.767867565155029, 'learning_rate': 4.7817159716131095e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8588, 'grad_norm': 9.402159690856934, 'learning_rate': 4.7807192408898816e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0759, 'grad_norm': 5.723330020904541, 'learning_rate': 4.779722510166654e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9791, 'grad_norm': 6.051968574523926, 'learning_rate': 4.778725779443426e-05, 'epoch': 0.05}\n",
      "{'loss': 2.1345, 'grad_norm': 6.79097843170166, 'learning_rate': 4.777729048720198e-05, 'epoch': 0.05}\n",
      "{'loss': 2.2653, 'grad_norm': 6.573770046234131, 'learning_rate': 4.77673231799697e-05, 'epoch': 0.05}\n",
      "{'loss': 2.7185, 'grad_norm': 5.49896240234375, 'learning_rate': 4.7757355872737424e-05, 'epoch': 0.05}\n",
      "{'loss': 1.6329, 'grad_norm': 7.88499641418457, 'learning_rate': 4.7747388565505145e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0883, 'grad_norm': 6.410362720489502, 'learning_rate': 4.773742125827287e-05, 'epoch': 0.05}\n",
      "{'loss': 2.4663, 'grad_norm': 5.628684997558594, 'learning_rate': 4.772745395104059e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9714, 'grad_norm': 6.519588470458984, 'learning_rate': 4.771748664380831e-05, 'epoch': 0.06}\n",
      "{'loss': 2.4551, 'grad_norm': 6.558073997497559, 'learning_rate': 4.770751933657603e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1813, 'grad_norm': 8.04043960571289, 'learning_rate': 4.769755202934375e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1338, 'grad_norm': 4.6906609535217285, 'learning_rate': 4.7687584722111475e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8274, 'grad_norm': 9.183656692504883, 'learning_rate': 4.76776174148792e-05, 'epoch': 0.06}\n",
      "{'loss': 2.7578, 'grad_norm': 4.957032203674316, 'learning_rate': 4.7667650107646925e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1966, 'grad_norm': 7.879002571105957, 'learning_rate': 4.7657682800414646e-05, 'epoch': 0.06}\n",
      "{'loss': 2.6627, 'grad_norm': 4.254720687866211, 'learning_rate': 4.764771549318237e-05, 'epoch': 0.06}\n",
      "{'loss': 2.4349, 'grad_norm': 6.5329766273498535, 'learning_rate': 4.763774818595009e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2253, 'grad_norm': 8.334786415100098, 'learning_rate': 4.762778087871781e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2921, 'grad_norm': 5.339755058288574, 'learning_rate': 4.761781357148553e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2359, 'grad_norm': 6.39843225479126, 'learning_rate': 4.7607846264253254e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0816, 'grad_norm': 7.92954683303833, 'learning_rate': 4.7597878957020975e-05, 'epoch': 0.06}\n",
      "{'loss': 1.6109, 'grad_norm': 4.426093578338623, 'learning_rate': 4.75879116497887e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9371, 'grad_norm': 7.539859294891357, 'learning_rate': 4.757794434255642e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1547, 'grad_norm': 6.425080299377441, 'learning_rate': 4.756797703532414e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7963, 'grad_norm': 9.488113403320312, 'learning_rate': 4.755800972809186e-05, 'epoch': 0.06}\n",
      "{'loss': 1.6784, 'grad_norm': 6.22783899307251, 'learning_rate': 4.754804242085958e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1728, 'grad_norm': 5.431695461273193, 'learning_rate': 4.7538075113627305e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0822, 'grad_norm': 13.908502578735352, 'learning_rate': 4.7528107806395026e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9701, 'grad_norm': 7.719690799713135, 'learning_rate': 4.751814049916275e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9656, 'grad_norm': 3.9828078746795654, 'learning_rate': 4.750817319193047e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9988, 'grad_norm': 6.344744682312012, 'learning_rate': 4.749820588469819e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9621, 'grad_norm': 15.057973861694336, 'learning_rate': 4.748823857746591e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8502, 'grad_norm': 8.445594787597656, 'learning_rate': 4.747827127023364e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0906, 'grad_norm': 7.277186870574951, 'learning_rate': 4.746830396300136e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9992, 'grad_norm': 6.208852767944336, 'learning_rate': 4.7458336655769084e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8175, 'grad_norm': 6.117866039276123, 'learning_rate': 4.7448369348536805e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2751, 'grad_norm': 6.56291389465332, 'learning_rate': 4.743840204130453e-05, 'epoch': 0.06}\n",
      "{'loss': 2.2269, 'grad_norm': 5.927543640136719, 'learning_rate': 4.742843473407225e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1784, 'grad_norm': 7.533295631408691, 'learning_rate': 4.741846742683997e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9436, 'grad_norm': 18.901735305786133, 'learning_rate': 4.740850011960769e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9093, 'grad_norm': 10.524002075195312, 'learning_rate': 4.739853281237541e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1076, 'grad_norm': 8.133556365966797, 'learning_rate': 4.7388565505143134e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7789, 'grad_norm': 6.154636383056641, 'learning_rate': 4.7378598197910856e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1315, 'grad_norm': 9.926947593688965, 'learning_rate': 4.736863089067858e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1157, 'grad_norm': 7.817506313323975, 'learning_rate': 4.73586635834463e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9368, 'grad_norm': 5.594114780426025, 'learning_rate': 4.734869627621402e-05, 'epoch': 0.06}\n",
      "{'loss': 2.245, 'grad_norm': 8.47677993774414, 'learning_rate': 4.733872896898174e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9774, 'grad_norm': 8.007430076599121, 'learning_rate': 4.7328761661749464e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0182, 'grad_norm': 6.377736568450928, 'learning_rate': 4.7318794354517185e-05, 'epoch': 0.06}\n",
      "{'loss': 2.238, 'grad_norm': 11.661161422729492, 'learning_rate': 4.730882704728491e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0454, 'grad_norm': 8.728157997131348, 'learning_rate': 4.729885974005263e-05, 'epoch': 0.06}\n",
      "{'loss': 2.4077, 'grad_norm': 5.218569278717041, 'learning_rate': 4.728889243282035e-05, 'epoch': 0.06}\n",
      "{'loss': 1.5808, 'grad_norm': 11.710359573364258, 'learning_rate': 4.727892512558808e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8444, 'grad_norm': 5.4330668449401855, 'learning_rate': 4.72689578183558e-05, 'epoch': 0.06}\n",
      "{'loss': 2.127, 'grad_norm': 6.341046333312988, 'learning_rate': 4.725899051112352e-05, 'epoch': 0.06}\n",
      "{'loss': 2.1066, 'grad_norm': 6.981154441833496, 'learning_rate': 4.724902320389124e-05, 'epoch': 0.06}\n",
      "{'loss': 1.942, 'grad_norm': 7.234949111938477, 'learning_rate': 4.7239055896658964e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0725, 'grad_norm': 5.727840900421143, 'learning_rate': 4.7229088589426686e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0626, 'grad_norm': 5.122596740722656, 'learning_rate': 4.721912128219441e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9032, 'grad_norm': 5.7656731605529785, 'learning_rate': 4.720915397496213e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1941, 'grad_norm': 4.597337245941162, 'learning_rate': 4.719918666772985e-05, 'epoch': 0.07}\n",
      "{'loss': 2.4083, 'grad_norm': 8.527807235717773, 'learning_rate': 4.718921936049757e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9907, 'grad_norm': 3.925370216369629, 'learning_rate': 4.7179252053265294e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7201, 'grad_norm': 8.17241382598877, 'learning_rate': 4.7169284746033015e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9758, 'grad_norm': 5.811643600463867, 'learning_rate': 4.715931743880074e-05, 'epoch': 0.07}\n",
      "{'loss': 2.3169, 'grad_norm': 11.960150718688965, 'learning_rate': 4.714935013156846e-05, 'epoch': 0.07}\n",
      "{'loss': 2.3433, 'grad_norm': 8.70901870727539, 'learning_rate': 4.713938282433618e-05, 'epoch': 0.07}\n",
      "{'loss': 2.4364, 'grad_norm': 14.341771125793457, 'learning_rate': 4.71294155171039e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1335, 'grad_norm': 7.810486793518066, 'learning_rate': 4.711944820987162e-05, 'epoch': 0.07}\n",
      "{'loss': 1.775, 'grad_norm': 6.404018402099609, 'learning_rate': 4.7109480902639344e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7765, 'grad_norm': 4.328479290008545, 'learning_rate': 4.7099513595407066e-05, 'epoch': 0.07}\n",
      "{'loss': 2.4518, 'grad_norm': 8.357295989990234, 'learning_rate': 4.708954628817479e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9813, 'grad_norm': 8.740946769714355, 'learning_rate': 4.7079578980942516e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1965, 'grad_norm': 8.378382682800293, 'learning_rate': 4.706961167371024e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9164, 'grad_norm': 13.545445442199707, 'learning_rate': 4.705964436647796e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8956, 'grad_norm': 5.978464126586914, 'learning_rate': 4.704967705924568e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1164, 'grad_norm': 7.800106048583984, 'learning_rate': 4.70397097520134e-05, 'epoch': 0.07}\n",
      "{'loss': 2.022, 'grad_norm': 5.052099704742432, 'learning_rate': 4.7029742444781124e-05, 'epoch': 0.07}\n",
      "{'loss': 2.3445, 'grad_norm': 8.913063049316406, 'learning_rate': 4.7019775137548845e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1505, 'grad_norm': 5.360228538513184, 'learning_rate': 4.700980783031657e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8426, 'grad_norm': 6.563063144683838, 'learning_rate': 4.699984052308429e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8516, 'grad_norm': 5.7522735595703125, 'learning_rate': 4.698987321585201e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0153, 'grad_norm': 9.943771362304688, 'learning_rate': 4.697990590861973e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1371, 'grad_norm': 6.475714206695557, 'learning_rate': 4.696993860138745e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0422, 'grad_norm': 10.642058372497559, 'learning_rate': 4.6959971294155174e-05, 'epoch': 0.07}\n",
      "{'loss': 2.2163, 'grad_norm': 5.764797687530518, 'learning_rate': 4.6950003986922896e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9776, 'grad_norm': 8.523652076721191, 'learning_rate': 4.694003667969062e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0699, 'grad_norm': 5.557001113891602, 'learning_rate': 4.693006937245834e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8422, 'grad_norm': 9.412874221801758, 'learning_rate': 4.692010206522606e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1443, 'grad_norm': 6.8912672996521, 'learning_rate': 4.691013475799378e-05, 'epoch': 0.07}\n",
      "{'loss': 1.819, 'grad_norm': 4.547675609588623, 'learning_rate': 4.6900167450761504e-05, 'epoch': 0.07}\n",
      "{'loss': 1.6996, 'grad_norm': 8.013242721557617, 'learning_rate': 4.6890200143529225e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7157, 'grad_norm': 6.179978370666504, 'learning_rate': 4.6880232836296953e-05, 'epoch': 0.07}\n",
      "{'loss': 1.85, 'grad_norm': 8.692612648010254, 'learning_rate': 4.6870265529064675e-05, 'epoch': 0.07}\n",
      "{'loss': 1.6404, 'grad_norm': 7.906238555908203, 'learning_rate': 4.6860298221832397e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7971, 'grad_norm': 6.709181785583496, 'learning_rate': 4.685033091460012e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7707, 'grad_norm': 8.008373260498047, 'learning_rate': 4.684036360736784e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1587, 'grad_norm': 10.067852020263672, 'learning_rate': 4.683039630013556e-05, 'epoch': 0.07}\n",
      "{'loss': 2.2307, 'grad_norm': 5.957651138305664, 'learning_rate': 4.682042899290328e-05, 'epoch': 0.07}\n",
      "{'loss': 1.5167, 'grad_norm': 7.96653938293457, 'learning_rate': 4.6810461685671004e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7104, 'grad_norm': 5.070674896240234, 'learning_rate': 4.6800494378438726e-05, 'epoch': 0.07}\n",
      "{'loss': 2.1941, 'grad_norm': 9.767926216125488, 'learning_rate': 4.679052707120645e-05, 'epoch': 0.07}\n",
      "{'loss': 2.105, 'grad_norm': 7.374927043914795, 'learning_rate': 4.678055976397417e-05, 'epoch': 0.07}\n",
      "{'loss': 2.3694, 'grad_norm': 9.025827407836914, 'learning_rate': 4.677059245674189e-05, 'epoch': 0.07}\n",
      "{'loss': 2.3208, 'grad_norm': 5.918149948120117, 'learning_rate': 4.676062514950961e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7624, 'grad_norm': 10.027462005615234, 'learning_rate': 4.6750657842277333e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0978, 'grad_norm': 6.031809329986572, 'learning_rate': 4.6740690535045055e-05, 'epoch': 0.07}\n",
      "{'loss': 1.4763, 'grad_norm': 5.420263767242432, 'learning_rate': 4.6730723227812777e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7218, 'grad_norm': 6.103114128112793, 'learning_rate': 4.67207559205805e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0472, 'grad_norm': 9.080894470214844, 'learning_rate': 4.671078861334822e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9654, 'grad_norm': 7.227895736694336, 'learning_rate': 4.670082130611594e-05, 'epoch': 0.08}\n",
      "{'loss': 2.4477, 'grad_norm': 14.16362476348877, 'learning_rate': 4.669085399888366e-05, 'epoch': 0.08}\n",
      "{'loss': 1.804, 'grad_norm': 8.405555725097656, 'learning_rate': 4.6680886691651384e-05, 'epoch': 0.08}\n",
      "{'loss': 2.225, 'grad_norm': 5.2769622802734375, 'learning_rate': 4.667091938441911e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0221, 'grad_norm': 4.639627456665039, 'learning_rate': 4.6660952077186834e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0579, 'grad_norm': 6.258591175079346, 'learning_rate': 4.6650984769954556e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7634, 'grad_norm': 7.258129119873047, 'learning_rate': 4.664101746272228e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0769, 'grad_norm': 8.336989402770996, 'learning_rate': 4.663105015549e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9913, 'grad_norm': 3.4929234981536865, 'learning_rate': 4.662108284825772e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0372, 'grad_norm': 7.052331447601318, 'learning_rate': 4.661111554102544e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9096, 'grad_norm': 7.302517414093018, 'learning_rate': 4.660114823379316e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8934, 'grad_norm': 8.223014831542969, 'learning_rate': 4.6591180926560885e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7176, 'grad_norm': 8.272336959838867, 'learning_rate': 4.6581213619328606e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7472, 'grad_norm': 5.510561943054199, 'learning_rate': 4.657124631209633e-05, 'epoch': 0.08}\n",
      "{'loss': 1.5886, 'grad_norm': 6.501601696014404, 'learning_rate': 4.656127900486405e-05, 'epoch': 0.08}\n",
      "{'loss': 1.87, 'grad_norm': 9.525798797607422, 'learning_rate': 4.655131169763177e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9747, 'grad_norm': 5.213412284851074, 'learning_rate': 4.654134439039949e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7467, 'grad_norm': 5.060206413269043, 'learning_rate': 4.6531377083167214e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9951, 'grad_norm': 3.826740264892578, 'learning_rate': 4.6521409775934936e-05, 'epoch': 0.08}\n",
      "{'loss': 2.122, 'grad_norm': 6.225057601928711, 'learning_rate': 4.651144246870266e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9853, 'grad_norm': 5.54783296585083, 'learning_rate': 4.650147516147038e-05, 'epoch': 0.08}\n",
      "{'loss': 2.2427, 'grad_norm': 5.135993957519531, 'learning_rate': 4.64915078542381e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0129, 'grad_norm': 6.511584758758545, 'learning_rate': 4.648154054700582e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8821, 'grad_norm': 7.748260021209717, 'learning_rate': 4.647157323977355e-05, 'epoch': 0.08}\n",
      "{'loss': 1.6146, 'grad_norm': 4.399821758270264, 'learning_rate': 4.646160593254127e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0403, 'grad_norm': 5.9225263595581055, 'learning_rate': 4.645163862530899e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1671, 'grad_norm': 5.894577980041504, 'learning_rate': 4.6441671318076715e-05, 'epoch': 0.08}\n",
      "{'loss': 1.769, 'grad_norm': 6.269240379333496, 'learning_rate': 4.6431704010844436e-05, 'epoch': 0.08}\n",
      "{'loss': 1.6436, 'grad_norm': 9.968023300170898, 'learning_rate': 4.642173670361216e-05, 'epoch': 0.08}\n",
      "{'loss': 1.5968, 'grad_norm': 10.397994041442871, 'learning_rate': 4.641176939637988e-05, 'epoch': 0.08}\n",
      "{'loss': 2.3765, 'grad_norm': 8.246136665344238, 'learning_rate': 4.64018020891476e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8595, 'grad_norm': 6.991231441497803, 'learning_rate': 4.639183478191532e-05, 'epoch': 0.08}\n",
      "{'loss': 1.928, 'grad_norm': 8.050885200500488, 'learning_rate': 4.6381867474683044e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9236, 'grad_norm': 4.750507354736328, 'learning_rate': 4.6371900167450766e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1939, 'grad_norm': 4.9251532554626465, 'learning_rate': 4.636193286021849e-05, 'epoch': 0.08}\n",
      "{'loss': 2.3213, 'grad_norm': 10.50676155090332, 'learning_rate': 4.635196555298621e-05, 'epoch': 0.08}\n",
      "{'loss': 2.3329, 'grad_norm': 6.093116760253906, 'learning_rate': 4.634199824575393e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0066, 'grad_norm': 5.380620002746582, 'learning_rate': 4.633203093852165e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7907, 'grad_norm': 10.971573829650879, 'learning_rate': 4.632206363128937e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9792, 'grad_norm': 5.64560604095459, 'learning_rate': 4.6312096324057095e-05, 'epoch': 0.08}\n",
      "{'loss': 2.145, 'grad_norm': 6.169234752655029, 'learning_rate': 4.6302129016824816e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1721, 'grad_norm': 12.206171989440918, 'learning_rate': 4.629216170959254e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0022, 'grad_norm': 6.164527416229248, 'learning_rate': 4.628219440236026e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8927, 'grad_norm': 9.65014934539795, 'learning_rate': 4.627222709512799e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0133, 'grad_norm': 4.725166320800781, 'learning_rate': 4.626225978789571e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9672, 'grad_norm': 10.604394912719727, 'learning_rate': 4.625229248066343e-05, 'epoch': 0.08}\n",
      "{'loss': 2.2652, 'grad_norm': 9.983707427978516, 'learning_rate': 4.624232517343115e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7623, 'grad_norm': 14.271656036376953, 'learning_rate': 4.6232357866198874e-05, 'epoch': 0.08}\n",
      "{'loss': 1.6795, 'grad_norm': 9.295013427734375, 'learning_rate': 4.6222390558966596e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8724, 'grad_norm': 5.083653926849365, 'learning_rate': 4.621242325173432e-05, 'epoch': 0.08}\n",
      "{'loss': 2.2925, 'grad_norm': 5.829723834991455, 'learning_rate': 4.620245594450204e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9482, 'grad_norm': 7.825235843658447, 'learning_rate': 4.619248863726976e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7944, 'grad_norm': 5.700448036193848, 'learning_rate': 4.618252133003748e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6533, 'grad_norm': 4.914172172546387, 'learning_rate': 4.61725540228052e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9829, 'grad_norm': 6.707358360290527, 'learning_rate': 4.6162586715572925e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6634, 'grad_norm': 5.091224193572998, 'learning_rate': 4.6152619408340646e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1253, 'grad_norm': 5.9122748374938965, 'learning_rate': 4.614265210110837e-05, 'epoch': 0.09}\n",
      "{'loss': 2.293, 'grad_norm': 5.3026628494262695, 'learning_rate': 4.613268479387609e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0768, 'grad_norm': 7.096686840057373, 'learning_rate': 4.612271748664381e-05, 'epoch': 0.09}\n",
      "{'loss': 1.5161, 'grad_norm': 6.96418571472168, 'learning_rate': 4.611275017941153e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7239, 'grad_norm': 4.876170635223389, 'learning_rate': 4.6102782872179254e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9093, 'grad_norm': 7.678581714630127, 'learning_rate': 4.6092815564946976e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2047, 'grad_norm': 6.074129104614258, 'learning_rate': 4.60828482577147e-05, 'epoch': 0.09}\n",
      "{'loss': 2.5104, 'grad_norm': 8.06617546081543, 'learning_rate': 4.6072880950482425e-05, 'epoch': 0.09}\n",
      "{'loss': 1.4342, 'grad_norm': 5.620492458343506, 'learning_rate': 4.606291364325015e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7961, 'grad_norm': 6.718430042266846, 'learning_rate': 4.605294633601787e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8584, 'grad_norm': 5.9520673751831055, 'learning_rate': 4.604297902878559e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7559, 'grad_norm': 3.704159736633301, 'learning_rate': 4.603301172155331e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7049, 'grad_norm': 5.798262596130371, 'learning_rate': 4.602304441432103e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1736, 'grad_norm': 6.454638957977295, 'learning_rate': 4.6013077107088755e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9151, 'grad_norm': 3.9299018383026123, 'learning_rate': 4.6003109799856476e-05, 'epoch': 0.09}\n",
      "{'loss': 2.4501, 'grad_norm': 6.160177230834961, 'learning_rate': 4.59931424926242e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6783, 'grad_norm': 8.703781127929688, 'learning_rate': 4.598317518539192e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9111, 'grad_norm': 7.317262172698975, 'learning_rate': 4.597320787815964e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9404, 'grad_norm': 2.8189539909362793, 'learning_rate': 4.596324057092736e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7318, 'grad_norm': 9.870012283325195, 'learning_rate': 4.5953273263695084e-05, 'epoch': 0.09}\n",
      "{'loss': 1.5084, 'grad_norm': 7.657764434814453, 'learning_rate': 4.5943305956462805e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1729, 'grad_norm': 6.1156840324401855, 'learning_rate': 4.593333864923053e-05, 'epoch': 0.09}\n",
      "{'loss': 2.213, 'grad_norm': 8.429524421691895, 'learning_rate': 4.592337134199825e-05, 'epoch': 0.09}\n",
      "{'loss': 2.3324, 'grad_norm': 5.131503105163574, 'learning_rate': 4.591340403476597e-05, 'epoch': 0.09}\n",
      "{'loss': 1.818, 'grad_norm': 7.317637920379639, 'learning_rate': 4.590343672753369e-05, 'epoch': 0.09}\n",
      "{'loss': 2.2991, 'grad_norm': 6.718008518218994, 'learning_rate': 4.589346942030141e-05, 'epoch': 0.09}\n",
      "{'loss': 2.3852, 'grad_norm': 12.685487747192383, 'learning_rate': 4.5883502113069135e-05, 'epoch': 0.09}\n",
      "{'loss': 1.592, 'grad_norm': 4.930750846862793, 'learning_rate': 4.587353480583686e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7557, 'grad_norm': 4.406400680541992, 'learning_rate': 4.5863567498604585e-05, 'epoch': 0.09}\n",
      "{'loss': 1.4511, 'grad_norm': 8.583283424377441, 'learning_rate': 4.5853600191372306e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8881, 'grad_norm': 6.6810526847839355, 'learning_rate': 4.584363288414003e-05, 'epoch': 0.09}\n",
      "{'loss': 1.806, 'grad_norm': 6.147839546203613, 'learning_rate': 4.583366557690775e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0151, 'grad_norm': 4.369385719299316, 'learning_rate': 4.582369826967547e-05, 'epoch': 0.09}\n",
      "{'loss': 1.872, 'grad_norm': 8.821385383605957, 'learning_rate': 4.581373096244319e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0461, 'grad_norm': 4.641257286071777, 'learning_rate': 4.5803763655210914e-05, 'epoch': 0.09}\n",
      "{'loss': 1.758, 'grad_norm': 6.769200801849365, 'learning_rate': 4.5793796347978635e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0702, 'grad_norm': 8.560922622680664, 'learning_rate': 4.578382904074636e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8129, 'grad_norm': 7.717686653137207, 'learning_rate': 4.577386173351408e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6727, 'grad_norm': 5.653515338897705, 'learning_rate': 4.57638944262818e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1057, 'grad_norm': 5.653003215789795, 'learning_rate': 4.575392711904952e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9335, 'grad_norm': 6.354181289672852, 'learning_rate': 4.574395981181724e-05, 'epoch': 0.09}\n",
      "{'loss': 1.4004, 'grad_norm': 6.27189302444458, 'learning_rate': 4.5733992504584965e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8873, 'grad_norm': 5.384008884429932, 'learning_rate': 4.5724025197352686e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1984, 'grad_norm': 6.626661777496338, 'learning_rate': 4.571405789012041e-05, 'epoch': 0.09}\n",
      "{'loss': 1.6345, 'grad_norm': 4.783277988433838, 'learning_rate': 4.570409058288813e-05, 'epoch': 0.09}\n",
      "{'loss': 1.915, 'grad_norm': 5.769372463226318, 'learning_rate': 4.569412327565585e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8571, 'grad_norm': 13.655549049377441, 'learning_rate': 4.568415596842357e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0954, 'grad_norm': 5.591654300689697, 'learning_rate': 4.5674188661191294e-05, 'epoch': 0.1}\n",
      "{'loss': 2.075, 'grad_norm': 10.869637489318848, 'learning_rate': 4.566422135395902e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7665, 'grad_norm': 4.627841949462891, 'learning_rate': 4.5654254046726744e-05, 'epoch': 0.1}\n",
      "{'loss': 1.791, 'grad_norm': 8.593222618103027, 'learning_rate': 4.5644286739494465e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9254, 'grad_norm': 5.294924259185791, 'learning_rate': 4.563431943226219e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8841, 'grad_norm': 4.392337799072266, 'learning_rate': 4.562435212502991e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1697, 'grad_norm': 10.621720314025879, 'learning_rate': 4.561438481779763e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7304, 'grad_norm': 5.9334187507629395, 'learning_rate': 4.560441751056535e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0498, 'grad_norm': 8.092711448669434, 'learning_rate': 4.559445020333307e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7919, 'grad_norm': 6.684837818145752, 'learning_rate': 4.5584482896100795e-05, 'epoch': 0.1}\n",
      "{'loss': 2.2987, 'grad_norm': 8.131612777709961, 'learning_rate': 4.5574515588868516e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8632, 'grad_norm': 7.781888484954834, 'learning_rate': 4.556454828163624e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7565, 'grad_norm': 4.987071514129639, 'learning_rate': 4.555458097440396e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9974, 'grad_norm': 3.9856624603271484, 'learning_rate': 4.554461366717168e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9176, 'grad_norm': 5.655633926391602, 'learning_rate': 4.55346463599394e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9858, 'grad_norm': 4.148871421813965, 'learning_rate': 4.5524679052707124e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8929, 'grad_norm': 6.529894828796387, 'learning_rate': 4.5514711745474845e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7113, 'grad_norm': 17.284530639648438, 'learning_rate': 4.550474443824257e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9096, 'grad_norm': 8.9902925491333, 'learning_rate': 4.549477713101029e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6312, 'grad_norm': 4.913726329803467, 'learning_rate': 4.548480982377801e-05, 'epoch': 0.1}\n",
      "{'loss': 1.805, 'grad_norm': 6.61986780166626, 'learning_rate': 4.547484251654573e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9731, 'grad_norm': 6.494266033172607, 'learning_rate': 4.546487520931346e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7747, 'grad_norm': 7.738338470458984, 'learning_rate': 4.545490790208118e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6255, 'grad_norm': 4.981052398681641, 'learning_rate': 4.54449405948489e-05, 'epoch': 0.1}\n",
      "{'loss': 1.809, 'grad_norm': 6.812743186950684, 'learning_rate': 4.5434973287616624e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6846, 'grad_norm': 6.5900797843933105, 'learning_rate': 4.5425005980384346e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0009, 'grad_norm': 4.768037796020508, 'learning_rate': 4.541503867315207e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7833, 'grad_norm': 9.495841026306152, 'learning_rate': 4.540507136591979e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6517, 'grad_norm': 6.492671489715576, 'learning_rate': 4.539510405868751e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0986, 'grad_norm': 16.277978897094727, 'learning_rate': 4.538513675145523e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9621, 'grad_norm': 7.840146064758301, 'learning_rate': 4.5375169444222954e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9968, 'grad_norm': 9.90335750579834, 'learning_rate': 4.5365202136990675e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7508, 'grad_norm': 7.271603107452393, 'learning_rate': 4.53552348297584e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0199, 'grad_norm': 8.281742095947266, 'learning_rate': 4.534526752252612e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6526, 'grad_norm': 8.410134315490723, 'learning_rate': 4.533530021529384e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8247, 'grad_norm': 4.300467491149902, 'learning_rate': 4.532533290806156e-05, 'epoch': 0.1}\n",
      "{'loss': 2.3924, 'grad_norm': 7.171439170837402, 'learning_rate': 4.531536560082928e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6801, 'grad_norm': 4.237999439239502, 'learning_rate': 4.5305398293597004e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0312, 'grad_norm': 9.325453758239746, 'learning_rate': 4.5295430986364726e-05, 'epoch': 0.1}\n",
      "{'loss': 2.3109, 'grad_norm': 6.453420162200928, 'learning_rate': 4.528546367913245e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9212, 'grad_norm': 5.961752891540527, 'learning_rate': 4.527549637190017e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8471, 'grad_norm': 6.658761501312256, 'learning_rate': 4.52655290646679e-05, 'epoch': 0.1}\n",
      "{'loss': 2.1772, 'grad_norm': 7.558850288391113, 'learning_rate': 4.525556175743562e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8523, 'grad_norm': 9.960466384887695, 'learning_rate': 4.524559445020334e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6096, 'grad_norm': 4.906250953674316, 'learning_rate': 4.523562714297106e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9667, 'grad_norm': 4.962157726287842, 'learning_rate': 4.5225659835738784e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8489, 'grad_norm': 7.943356037139893, 'learning_rate': 4.5215692528506505e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9187, 'grad_norm': 6.824074745178223, 'learning_rate': 4.520572522127423e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7925, 'grad_norm': 15.032729148864746, 'learning_rate': 4.519575791404195e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8248, 'grad_norm': 6.819509983062744, 'learning_rate': 4.518579060680966e-05, 'epoch': 0.11}\n",
      "{'loss': 2.3804, 'grad_norm': 9.164962768554688, 'learning_rate': 4.5175823299577385e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0956, 'grad_norm': 9.200380325317383, 'learning_rate': 4.5165855992345106e-05, 'epoch': 0.11}\n",
      "{'loss': 1.5995, 'grad_norm': 5.290910720825195, 'learning_rate': 4.515588868511283e-05, 'epoch': 0.11}\n",
      "{'loss': 1.5841, 'grad_norm': 15.0443754196167, 'learning_rate': 4.514592137788055e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8666, 'grad_norm': 7.079737663269043, 'learning_rate': 4.513595407064827e-05, 'epoch': 0.11}\n",
      "{'loss': 2.3657, 'grad_norm': 7.619561195373535, 'learning_rate': 4.512598676341599e-05, 'epoch': 0.11}\n",
      "{'loss': 2.1916, 'grad_norm': 8.292428970336914, 'learning_rate': 4.5116019456183714e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0587, 'grad_norm': 6.825443267822266, 'learning_rate': 4.5106052148951435e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2066, 'grad_norm': 6.700117588043213, 'learning_rate': 4.5096084841719164e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0294, 'grad_norm': 8.72309398651123, 'learning_rate': 4.5086117534486885e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9456, 'grad_norm': 4.634532928466797, 'learning_rate': 4.507615022725461e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8153, 'grad_norm': 3.3159234523773193, 'learning_rate': 4.506618292002233e-05, 'epoch': 0.11}\n",
      "{'loss': 2.1414, 'grad_norm': 10.081331253051758, 'learning_rate': 4.505621561279005e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2599, 'grad_norm': 6.475030899047852, 'learning_rate': 4.504624830555777e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7973, 'grad_norm': 5.675118446350098, 'learning_rate': 4.503628099832549e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2877, 'grad_norm': 7.059848308563232, 'learning_rate': 4.5026313691093214e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6415, 'grad_norm': 7.575085639953613, 'learning_rate': 4.5016346383860936e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7937, 'grad_norm': 7.947636604309082, 'learning_rate': 4.500637907662866e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7886, 'grad_norm': 7.657435894012451, 'learning_rate': 4.499641176939638e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0843, 'grad_norm': 7.709780216217041, 'learning_rate': 4.49864444621641e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0139, 'grad_norm': 3.476552724838257, 'learning_rate': 4.497647715493182e-05, 'epoch': 0.11}\n",
      "{'loss': 1.903, 'grad_norm': 8.739163398742676, 'learning_rate': 4.4966509847699544e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6761, 'grad_norm': 5.784749507904053, 'learning_rate': 4.4956542540467265e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0027, 'grad_norm': 6.441291809082031, 'learning_rate': 4.494657523323499e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7683, 'grad_norm': 7.228295803070068, 'learning_rate': 4.493660792600271e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6632, 'grad_norm': 7.483953952789307, 'learning_rate': 4.492664061877043e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9262, 'grad_norm': 5.440151691436768, 'learning_rate': 4.491667331153815e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7699, 'grad_norm': 10.918888092041016, 'learning_rate': 4.490670600430587e-05, 'epoch': 0.11}\n",
      "{'loss': 2.2122, 'grad_norm': 6.571110725402832, 'learning_rate': 4.48967386970736e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7873, 'grad_norm': 5.970058441162109, 'learning_rate': 4.488677138984132e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8801, 'grad_norm': 10.362451553344727, 'learning_rate': 4.4876804082609044e-05, 'epoch': 0.11}\n",
      "{'loss': 1.5287, 'grad_norm': 4.690004825592041, 'learning_rate': 4.4866836775376766e-05, 'epoch': 0.11}\n",
      "{'loss': 2.01, 'grad_norm': 8.091279029846191, 'learning_rate': 4.485686946814449e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9747, 'grad_norm': 7.872535228729248, 'learning_rate': 4.484690216091221e-05, 'epoch': 0.11}\n",
      "{'loss': 2.17, 'grad_norm': 6.45338773727417, 'learning_rate': 4.483693485367993e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9272, 'grad_norm': 5.450963020324707, 'learning_rate': 4.482696754644765e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8598, 'grad_norm': 10.677371978759766, 'learning_rate': 4.4817000239215374e-05, 'epoch': 0.11}\n",
      "{'loss': 1.827, 'grad_norm': 6.598518371582031, 'learning_rate': 4.4807032931983095e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6238, 'grad_norm': 6.865970611572266, 'learning_rate': 4.479706562475082e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6215, 'grad_norm': 6.427274703979492, 'learning_rate': 4.478709831751854e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7927, 'grad_norm': 5.139044284820557, 'learning_rate': 4.477713101028626e-05, 'epoch': 0.11}\n",
      "{'loss': 1.3259, 'grad_norm': 7.072134971618652, 'learning_rate': 4.476716370305398e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7589, 'grad_norm': 10.668347358703613, 'learning_rate': 4.47571963958217e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6457, 'grad_norm': 7.027358055114746, 'learning_rate': 4.4747229088589424e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8011, 'grad_norm': 5.669284343719482, 'learning_rate': 4.4737261781357146e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9073, 'grad_norm': 7.4300537109375, 'learning_rate': 4.472729447412487e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7825, 'grad_norm': 8.088404655456543, 'learning_rate': 4.471732716689259e-05, 'epoch': 0.11}\n",
      "{'loss': 1.952, 'grad_norm': 12.089286804199219, 'learning_rate': 4.470735985966031e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8183, 'grad_norm': 4.9996185302734375, 'learning_rate': 4.469739255242804e-05, 'epoch': 0.11}\n",
      "{'loss': 1.5013, 'grad_norm': 11.16855239868164, 'learning_rate': 4.468742524519576e-05, 'epoch': 0.12}\n",
      "{'loss': 1.5777, 'grad_norm': 7.835306167602539, 'learning_rate': 4.467745793796348e-05, 'epoch': 0.12}\n",
      "{'loss': 2.3244, 'grad_norm': 5.778191566467285, 'learning_rate': 4.4667490630731204e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8869, 'grad_norm': 4.6694159507751465, 'learning_rate': 4.4657523323498925e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9047, 'grad_norm': 9.770614624023438, 'learning_rate': 4.4647556016266647e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2162, 'grad_norm': 6.565846920013428, 'learning_rate': 4.463758870903437e-05, 'epoch': 0.12}\n",
      "{'loss': 2.3491, 'grad_norm': 8.466209411621094, 'learning_rate': 4.462762140180209e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8202, 'grad_norm': 6.745100498199463, 'learning_rate': 4.461765409456981e-05, 'epoch': 0.12}\n",
      "{'loss': 1.83, 'grad_norm': 4.385101318359375, 'learning_rate': 4.460768678733753e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9954, 'grad_norm': 5.095746994018555, 'learning_rate': 4.4597719480105254e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8658, 'grad_norm': 9.836438179016113, 'learning_rate': 4.4587752172872976e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8624, 'grad_norm': 6.193245887756348, 'learning_rate': 4.45777848656407e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9162, 'grad_norm': 6.256026744842529, 'learning_rate': 4.456781755840842e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9502, 'grad_norm': 5.433593273162842, 'learning_rate': 4.455785025117614e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9729, 'grad_norm': 4.405658721923828, 'learning_rate': 4.454788294394386e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0172, 'grad_norm': 6.476260185241699, 'learning_rate': 4.4537915636711584e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9584, 'grad_norm': 7.441421031951904, 'learning_rate': 4.4527948329479305e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6894, 'grad_norm': 8.486884117126465, 'learning_rate': 4.451798102224703e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8441, 'grad_norm': 13.366800308227539, 'learning_rate': 4.450801371501475e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7597, 'grad_norm': 6.422980308532715, 'learning_rate': 4.4498046407782476e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9258, 'grad_norm': 5.856421947479248, 'learning_rate': 4.44880791005502e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9891, 'grad_norm': 7.841418266296387, 'learning_rate': 4.447811179331792e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7656, 'grad_norm': 7.236344337463379, 'learning_rate': 4.446814448608564e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1446, 'grad_norm': 11.149267196655273, 'learning_rate': 4.445817717885336e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7539, 'grad_norm': 7.502572059631348, 'learning_rate': 4.4448209871621084e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1932, 'grad_norm': 10.529451370239258, 'learning_rate': 4.4438242564388806e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7724, 'grad_norm': 4.029323101043701, 'learning_rate': 4.442827525715653e-05, 'epoch': 0.12}\n",
      "{'loss': 1.3467, 'grad_norm': 3.8584096431732178, 'learning_rate': 4.441830794992425e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7711, 'grad_norm': 10.33263111114502, 'learning_rate': 4.440834064269197e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6376, 'grad_norm': 9.529778480529785, 'learning_rate': 4.439837333545969e-05, 'epoch': 0.12}\n",
      "{'loss': 1.739, 'grad_norm': 5.2198944091796875, 'learning_rate': 4.4388406028227413e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8194, 'grad_norm': 5.370487689971924, 'learning_rate': 4.4378438720995135e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6051, 'grad_norm': 5.686013221740723, 'learning_rate': 4.4368471413762857e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1872, 'grad_norm': 7.879212379455566, 'learning_rate': 4.435850410653058e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6006, 'grad_norm': 7.514163017272949, 'learning_rate': 4.43485367992983e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0607, 'grad_norm': 6.674896717071533, 'learning_rate': 4.433856949206602e-05, 'epoch': 0.12}\n",
      "{'loss': 1.3788, 'grad_norm': 8.356529235839844, 'learning_rate': 4.432860218483374e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6507, 'grad_norm': 6.98423957824707, 'learning_rate': 4.4318634877601464e-05, 'epoch': 0.12}\n",
      "{'loss': 1.759, 'grad_norm': 5.624091148376465, 'learning_rate': 4.4308667570369186e-05, 'epoch': 0.12}\n",
      "{'loss': 1.5805, 'grad_norm': 8.464442253112793, 'learning_rate': 4.4298700263136914e-05, 'epoch': 0.12}\n",
      "{'loss': 2.2945, 'grad_norm': 7.542060852050781, 'learning_rate': 4.4288732955904636e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8479, 'grad_norm': 8.968053817749023, 'learning_rate': 4.427876564867236e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9811, 'grad_norm': 7.982638835906982, 'learning_rate': 4.426879834144008e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0924, 'grad_norm': 11.844343185424805, 'learning_rate': 4.42588310342078e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6572, 'grad_norm': 4.852343559265137, 'learning_rate': 4.424886372697552e-05, 'epoch': 0.12}\n",
      "{'loss': 1.6243, 'grad_norm': 6.177034378051758, 'learning_rate': 4.423889641974324e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0297, 'grad_norm': 5.726367950439453, 'learning_rate': 4.4228929112510965e-05, 'epoch': 0.12}\n",
      "{'loss': 1.4784, 'grad_norm': 5.682488918304443, 'learning_rate': 4.4218961805278686e-05, 'epoch': 0.12}\n",
      "{'loss': 1.908, 'grad_norm': 11.560959815979004, 'learning_rate': 4.420899449804641e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9028, 'grad_norm': 5.469382286071777, 'learning_rate': 4.419902719081413e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1793, 'grad_norm': 5.164318561553955, 'learning_rate': 4.418905988358185e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9618, 'grad_norm': 6.871883392333984, 'learning_rate': 4.417909257634957e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9592, 'grad_norm': 5.5574212074279785, 'learning_rate': 4.4169125269117294e-05, 'epoch': 0.13}\n",
      "{'loss': 1.92, 'grad_norm': 9.324520111083984, 'learning_rate': 4.4159157961885016e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0274, 'grad_norm': 8.998167037963867, 'learning_rate': 4.414919065465274e-05, 'epoch': 0.13}\n",
      "{'loss': 2.2685, 'grad_norm': 6.808281898498535, 'learning_rate': 4.413922334742046e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6186, 'grad_norm': 10.534005165100098, 'learning_rate': 4.412925604018818e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6685, 'grad_norm': 5.463327407836914, 'learning_rate': 4.41192887329559e-05, 'epoch': 0.13}\n",
      "{'loss': 2.3584, 'grad_norm': 8.211138725280762, 'learning_rate': 4.4109321425723623e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0915, 'grad_norm': 3.8237991333007812, 'learning_rate': 4.409935411849135e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6543, 'grad_norm': 6.938595294952393, 'learning_rate': 4.408938681125907e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7249, 'grad_norm': 9.16349983215332, 'learning_rate': 4.4079419504026795e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8118, 'grad_norm': 6.198367118835449, 'learning_rate': 4.4069452196794516e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9862, 'grad_norm': 9.19600772857666, 'learning_rate': 4.405948488956224e-05, 'epoch': 0.13}\n",
      "{'loss': 2.2676, 'grad_norm': 8.648360252380371, 'learning_rate': 4.404951758232996e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8236, 'grad_norm': 10.996672630310059, 'learning_rate': 4.403955027509768e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7613, 'grad_norm': 10.486204147338867, 'learning_rate': 4.40295829678654e-05, 'epoch': 0.13}\n",
      "{'loss': 1.898, 'grad_norm': 5.117055892944336, 'learning_rate': 4.4019615660633124e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8549, 'grad_norm': 8.101905822753906, 'learning_rate': 4.4009648353400846e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9483, 'grad_norm': 7.264110565185547, 'learning_rate': 4.399968104616857e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0227, 'grad_norm': 6.126112461090088, 'learning_rate': 4.398971373893629e-05, 'epoch': 0.13}\n",
      "{'loss': 1.5569, 'grad_norm': 8.050599098205566, 'learning_rate': 4.397974643170401e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0037, 'grad_norm': 4.2819342613220215, 'learning_rate': 4.396977912447173e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7529, 'grad_norm': 6.145827770233154, 'learning_rate': 4.395981181723945e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0254, 'grad_norm': 13.15407657623291, 'learning_rate': 4.3949844510007175e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7361, 'grad_norm': 7.172657012939453, 'learning_rate': 4.3939877202774896e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9976, 'grad_norm': 9.194587707519531, 'learning_rate': 4.392990989554262e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6661, 'grad_norm': 4.768687725067139, 'learning_rate': 4.391994258831034e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9475, 'grad_norm': 5.9924702644348145, 'learning_rate': 4.390997528107806e-05, 'epoch': 0.13}\n",
      "{'loss': 2.1193, 'grad_norm': 6.316600799560547, 'learning_rate': 4.390000797384578e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8619, 'grad_norm': 5.888421535491943, 'learning_rate': 4.389004066661351e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9053, 'grad_norm': 8.89768123626709, 'learning_rate': 4.388007335938123e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9073, 'grad_norm': 6.359599590301514, 'learning_rate': 4.3870106052148954e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0709, 'grad_norm': 5.898871898651123, 'learning_rate': 4.3860138744916676e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8343, 'grad_norm': 6.706732273101807, 'learning_rate': 4.38501714376844e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0594, 'grad_norm': 6.5733866691589355, 'learning_rate': 4.384020413045212e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8491, 'grad_norm': 8.054262161254883, 'learning_rate': 4.383023682321984e-05, 'epoch': 0.13}\n",
      "{'loss': 1.761, 'grad_norm': 4.938473224639893, 'learning_rate': 4.382026951598756e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0692, 'grad_norm': 6.6221113204956055, 'learning_rate': 4.381030220875528e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8202, 'grad_norm': 11.490925788879395, 'learning_rate': 4.3800334901523005e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8829, 'grad_norm': 4.531493663787842, 'learning_rate': 4.3790367594290726e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9601, 'grad_norm': 10.599039077758789, 'learning_rate': 4.378040028705845e-05, 'epoch': 0.13}\n",
      "{'loss': 1.4912, 'grad_norm': 5.000704288482666, 'learning_rate': 4.377043297982617e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6581, 'grad_norm': 7.117203235626221, 'learning_rate': 4.376046567259389e-05, 'epoch': 0.13}\n",
      "{'loss': 1.4099, 'grad_norm': 5.224034786224365, 'learning_rate': 4.375049836536161e-05, 'epoch': 0.13}\n",
      "{'loss': 2.2892, 'grad_norm': 6.785741329193115, 'learning_rate': 4.3740531058129334e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7681, 'grad_norm': 10.467032432556152, 'learning_rate': 4.3730563750897056e-05, 'epoch': 0.13}\n",
      "{'loss': 1.603, 'grad_norm': 8.134041786193848, 'learning_rate': 4.372059644366478e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 75\u001b[0m\n\u001b[1;32m     67\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     68\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     69\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m     70\u001b[0m     train_dataset\u001b[39m=\u001b[39mtrain_dataset,\n\u001b[1;32m     71\u001b[0m     eval_dataset\u001b[39m=\u001b[39mtest_dataset\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     77\u001b[0m \u001b[39m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     78\u001b[0m results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1886\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1887\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1888\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1889\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1890\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:2221\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2215\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m   2216\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2218\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2221\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39;49misinf(tr_loss_step))\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2225\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming the data is already loaded and cleaned, with 'Model' and 'Make_corrected' columns\n",
    "\n",
    "# Prepare features and target\n",
    "X = data['Model'].fillna('missing')\n",
    "y = data['Make_corrected'].astype(str)  # Ensure all values are strings\n",
    "\n",
    "# Encode the target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert all entries in X_train and X_test to strings\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the data\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=64)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=64)\n",
    "\n",
    "# Create a custom dataset class\n",
    "class EquipmentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset objects\n",
    "train_dataset = EquipmentDataset(train_encodings, y_train)\n",
    "test_dataset = EquipmentDataset(test_encodings, y_test)\n",
    "\n",
    "# Load the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_encoder.classes_))\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    fp16=False  # Ensure fp16 is disabled if using CPU\n",
    ")\n",
    "\n",
    "# Create the Trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "\n",
    "# Print the results\n",
    "print(results)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = trainer.predict(test_dataset).predictions.argmax(-1)\n",
    "\n",
    "# Decode the predictions and true labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print precision, recall, and f1-score\n",
    "\n",
    "\n",
    "sccj5nt gbn   umm  jfrom sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test_decoded, y_pred_decoded, average='weighted')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection Summary\n",
    "Start Simple: Begin with simple models to set a baseline.\n",
    "\n",
    "Experiment: Test more complex models and tune hyperparameters.\n",
    "\n",
    "Evaluate: Use appropriate metrics to evaluate model performance.\n",
    "\n",
    "Advanced Models: Consider using advanced models like BERT for improved performance.\n",
    "\n",
    "Final Selection: Choose the model that balances performance, interpretability, and deployment constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming Random Forest performed the best\n",
    "best_model = clf_rf\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('best_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "# Save the vectorizer to a file\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n",
    "\n",
    "# Save the label encoder to a file\n",
    "with open('label_encoder.pkl', 'wb') as le_file:\n",
    "    pickle.dump(label_encoder, le_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. What other supplemental information would be useful here?\n",
    "\n",
    "1. Metadata about the Equipment\n",
    "\n",
    "Year of Manufacture: Knowing when the equipment was made can help identify common models for specific years.\n",
    "\n",
    "Serial Number Patterns: Serial numbers might contain embedded information about the make or manufacturing process.\n",
    "\n",
    "Equipment Type or Category: Categorizing the equipment into broader types (e.g., HVAC, industrial, consumer) can narrow down the possible makes.\n",
    "\n",
    "2. Contextual Information\n",
    "\n",
    "Geographic Location: The location where the equipment is being used can be indicative of the make, as certain brands may be more prevalent in specific regions.\n",
    "\n",
    "Usage Data: Information about how the equipment is used can provide clues about the make. For example, industrial equipment may have different makes compared to consumer equipment.\n",
    "\n",
    "3. Historical Data\n",
    "\n",
    "Previous Repairs and Maintenance Records: Historical data on repairs and maintenance can help identify the make based on the frequency and type of issues.\n",
    "\n",
    "Warranty Information: Warranty data might provide direct information about the make and model.\n",
    "\n",
    "4. External Data Sources\n",
    "\n",
    "Industry Databases: Access to external databases that catalog equipment models and makes can provide additional validation.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
